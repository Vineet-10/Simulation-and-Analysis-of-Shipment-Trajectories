{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ab8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65af4128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                  timestamp  msg_type  repeat       mmsi  status  \\\n",
      "0  3700533 2025-03-08 10:26:16.403407         1       0  211572680     0.0   \n",
      "1  3700534 2025-03-08 10:26:17.001696         1       0  211478290     0.0   \n",
      "2  3700535 2025-03-08 10:26:17.432819         1       0  211668170    15.0   \n",
      "3  3700536 2025-03-08 10:26:17.513798         1       0  244660836     0.0   \n",
      "4  3700537 2025-03-08 10:26:19.133889         1       0  211668170    15.0   \n",
      "\n",
      "    turn  speed accuracy       lon  ...  offset1_2  spare_3  type2_1  \\\n",
      "0 -128.0    3.2     True  8.315200  ...        NaN      NaN      NaN   \n",
      "1    0.0    0.1     True  8.307820  ...        NaN      NaN      NaN   \n",
      "2 -128.0   18.2    False  8.280108  ...        NaN      NaN      NaN   \n",
      "3 -128.0    4.4     True  8.324817  ...        NaN      NaN      NaN   \n",
      "4 -128.0   18.5    False  8.280207  ...        NaN      NaN      NaN   \n",
      "\n",
      "   offset2_1  spare_4 year partno  vendorid  model  serial  \n",
      "0        NaN      NaN  NaN    NaN       NaN    NaN     NaN  \n",
      "1        NaN      NaN  NaN    NaN       NaN    NaN     NaN  \n",
      "2        NaN      NaN  NaN    NaN       NaN    NaN     NaN  \n",
      "3        NaN      NaN  NaN    NaN       NaN    NaN     NaN  \n",
      "4        NaN      NaN  NaN    NaN       NaN    NaN     NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id           150000\n",
       "timestamp    150000\n",
       "msg_type     150000\n",
       "repeat       150000\n",
       "mmsi         150000\n",
       "              ...  \n",
       "year             24\n",
       "partno            6\n",
       "vendorid          6\n",
       "model             6\n",
       "serial            6\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "def load_ais_data(file_path):\n",
    "\n",
    "    df = pd.read_csv(file_path, header=None, names=['id', 'timestamp', 'data'])\n",
    "\n",
    "    # Parse the JSON data in the 'data' column\n",
    "    df['data'] = df['data'].apply(json.loads)\n",
    "\n",
    "    # Expand the JSON data into separate columns\n",
    "    data_df = pd.json_normalize(df['data'])\n",
    "\n",
    "    # Combine with the original DataFrame\n",
    "    df = pd.concat([df.drop('data', axis=1), data_df], axis=1)\n",
    "\n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "file_path = 'rhein.csv'\n",
    "ais_data = load_ais_data(file_path)\n",
    "\n",
    "print(ais_data.head())\n",
    "ais_data.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fa61e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>velocity_x</th>\n",
       "      <th>velocity_y</th>\n",
       "      <th>gradient_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-08 10:26:16.403407</td>\n",
       "      <td>49.015880</td>\n",
       "      <td>8.315200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211478290</td>\n",
       "      <td>2025-03-08 10:26:17.001696</td>\n",
       "      <td>49.016428</td>\n",
       "      <td>8.307820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211668170</td>\n",
       "      <td>2025-03-08 10:26:17.432819</td>\n",
       "      <td>48.991250</td>\n",
       "      <td>8.280108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244660836</td>\n",
       "      <td>2025-03-08 10:26:17.513798</td>\n",
       "      <td>49.069933</td>\n",
       "      <td>8.324817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211668170</td>\n",
       "      <td>2025-03-08 10:26:19.133889</td>\n",
       "      <td>48.991307</td>\n",
       "      <td>8.280207</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.522403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>205437990</td>\n",
       "      <td>2025-03-08 10:26:20.928263</td>\n",
       "      <td>49.020410</td>\n",
       "      <td>8.300710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>211668170</td>\n",
       "      <td>2025-03-08 10:26:21.099798</td>\n",
       "      <td>48.991423</td>\n",
       "      <td>8.280402</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.536640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>269057351</td>\n",
       "      <td>2025-03-08 10:26:23.155308</td>\n",
       "      <td>49.000200</td>\n",
       "      <td>8.288200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>211668170</td>\n",
       "      <td>2025-03-08 10:26:23.312854</td>\n",
       "      <td>48.991538</td>\n",
       "      <td>8.280600</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.526188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>211632780</td>\n",
       "      <td>2025-03-08 10:26:23.488851</td>\n",
       "      <td>48.978873</td>\n",
       "      <td>8.255463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mmsi                  timestamp        lat       lon  velocity_x  \\\n",
       "0  211572680 2025-03-08 10:26:16.403407  49.015880  8.315200         NaN   \n",
       "1  211478290 2025-03-08 10:26:17.001696  49.016428  8.307820         NaN   \n",
       "2  211668170 2025-03-08 10:26:17.432819  48.991250  8.280108         NaN   \n",
       "3  244660836 2025-03-08 10:26:17.513798  49.069933  8.324817         NaN   \n",
       "4  211668170 2025-03-08 10:26:19.133889  48.991307  8.280207    0.000058   \n",
       "5  205437990 2025-03-08 10:26:20.928263  49.020410  8.300710         NaN   \n",
       "6  211668170 2025-03-08 10:26:21.099798  48.991423  8.280402    0.000099   \n",
       "7  269057351 2025-03-08 10:26:23.155308  49.000200  8.288200         NaN   \n",
       "8  211668170 2025-03-08 10:26:23.312854  48.991538  8.280600    0.000089   \n",
       "9  211632780 2025-03-08 10:26:23.488851  48.978873  8.255463         NaN   \n",
       "\n",
       "   velocity_y  gradient_info  \n",
       "0         NaN            NaN  \n",
       "1         NaN            NaN  \n",
       "2         NaN            NaN  \n",
       "3         NaN            NaN  \n",
       "4    0.000034       0.522403  \n",
       "5         NaN            NaN  \n",
       "6    0.000059       0.536640  \n",
       "7         NaN            NaN  \n",
       "8    0.000052       0.526188  \n",
       "9         NaN            NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "features = ['lat', 'lon', 'velocity_x', 'velocity_y', 'gradient_info']\n",
    "target = ['lat', 'lon', 'velocity_x', 'velocity_y', 'gradient_info']\n",
    "\n",
    "# Group by MMSI to calculate velocity components for each vessel separately\n",
    "ais_data['velocity_x'] = ais_data.groupby('mmsi')['lon'].diff() / ais_data.groupby('mmsi')['timestamp'].diff().dt.total_seconds()\n",
    "ais_data['velocity_y'] = ais_data.groupby('mmsi')['lat'].diff() / ais_data.groupby('mmsi')['timestamp'].diff().dt.total_seconds()\n",
    "\n",
    "# Calculate the gradient (direction of movement)\n",
    "ais_data['gradient_info'] = np.arctan2(ais_data['velocity_y'], ais_data['velocity_x'])  # Gradient as angle (direction)\n",
    "\n",
    "# Display the updated data with velocity and gradient columns\n",
    "ais_data[['mmsi', 'timestamp', 'lat', 'lon', 'velocity_x', 'velocity_y', 'gradient_info']].head(10)\n",
    "\n",
    "# print(ais_data['velocity_x'].head(10))\n",
    "# print(ais_data['velocity_y'].head(10))\n",
    "# print(ais_data['velocity_x'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77eaee72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>velocity_x</th>\n",
       "      <th>velocity_y</th>\n",
       "      <th>gradient_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-08 10:26:16.403407</td>\n",
       "      <td>49.015880</td>\n",
       "      <td>8.315200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-08 10:26:26.593755</td>\n",
       "      <td>49.015872</td>\n",
       "      <td>8.315450</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-7.850566e-07</td>\n",
       "      <td>-0.031989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-08 10:26:37.222831</td>\n",
       "      <td>49.015865</td>\n",
       "      <td>8.315687</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-6.585709e-07</td>\n",
       "      <td>-0.029527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-08 10:26:47.210330</td>\n",
       "      <td>49.015858</td>\n",
       "      <td>8.315927</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-7.008762e-07</td>\n",
       "      <td>-0.029158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-08 10:26:56.765464</td>\n",
       "      <td>49.015853</td>\n",
       "      <td>8.316175</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-5.232789e-07</td>\n",
       "      <td>-0.020159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146326</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-11 02:23:31.749434</td>\n",
       "      <td>48.961820</td>\n",
       "      <td>8.211675</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-3.600358e-06</td>\n",
       "      <td>-2.979091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146349</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-11 02:24:21.749037</td>\n",
       "      <td>48.961642</td>\n",
       "      <td>8.210543</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-3.560028e-06</td>\n",
       "      <td>-2.985626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146424</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-11 02:27:13.009443</td>\n",
       "      <td>48.961037</td>\n",
       "      <td>8.206782</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-3.532632e-06</td>\n",
       "      <td>-2.982098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146730</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-11 02:39:32.608862</td>\n",
       "      <td>48.955032</td>\n",
       "      <td>8.193152</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-8.119260e-06</td>\n",
       "      <td>-2.726606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146770</th>\n",
       "      <td>211572680</td>\n",
       "      <td>2025-03-11 02:40:51.520785</td>\n",
       "      <td>48.954047</td>\n",
       "      <td>8.192283</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-1.248227e-05</td>\n",
       "      <td>-2.293709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mmsi                  timestamp        lat       lon  velocity_x  \\\n",
       "0       211572680 2025-03-08 10:26:16.403407  49.015880  8.315200         NaN   \n",
       "12      211572680 2025-03-08 10:26:26.593755  49.015872  8.315450    0.000025   \n",
       "26      211572680 2025-03-08 10:26:37.222831  49.015865  8.315687    0.000022   \n",
       "37      211572680 2025-03-08 10:26:47.210330  49.015858  8.315927    0.000024   \n",
       "49      211572680 2025-03-08 10:26:56.765464  49.015853  8.316175    0.000026   \n",
       "...           ...                        ...        ...       ...         ...   \n",
       "146326  211572680 2025-03-11 02:23:31.749434  48.961820  8.211675   -0.000022   \n",
       "146349  211572680 2025-03-11 02:24:21.749037  48.961642  8.210543   -0.000023   \n",
       "146424  211572680 2025-03-11 02:27:13.009443  48.961037  8.206782   -0.000022   \n",
       "146730  211572680 2025-03-11 02:39:32.608862  48.955032  8.193152   -0.000018   \n",
       "146770  211572680 2025-03-11 02:40:51.520785  48.954047  8.192283   -0.000011   \n",
       "\n",
       "          velocity_y  gradient_info  \n",
       "0                NaN            NaN  \n",
       "12     -7.850566e-07      -0.031989  \n",
       "26     -6.585709e-07      -0.029527  \n",
       "37     -7.008762e-07      -0.029158  \n",
       "49     -5.232789e-07      -0.020159  \n",
       "...              ...            ...  \n",
       "146326 -3.600358e-06      -2.979091  \n",
       "146349 -3.560028e-06      -2.985626  \n",
       "146424 -3.532632e-06      -2.982098  \n",
       "146730 -8.119260e-06      -2.726606  \n",
       "146770 -1.248227e-05      -2.293709  \n",
       "\n",
       "[1459 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a specific MMSI ID (e.g., 211572680)\n",
    "mmsi_id = 211572680\n",
    "\n",
    "# Filter the dataset for that specific MMSI ID\n",
    "filtered_data = ais_data[(ais_data['mmsi'] == mmsi_id) & (ais_data['msg_type'] == 1)]\n",
    "\n",
    "# Display the first 10 rows for that MMSI\n",
    "filtered_data[['mmsi', 'timestamp', 'lat', 'lon', 'velocity_x', 'velocity_y', 'gradient_info']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5f80212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features and target using MinMaxScaler\n",
    "cols = list(dict.fromkeys(features + target))  # ['lat','lon','velocity_x','velocity_y','gradient_info']\n",
    "\n",
    "# drop any rows where these five columns are NaN\n",
    "\n",
    "clean = ais_data.dropna(subset=cols)\n",
    "# 2. Scale only the unique columns\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = clean[cols].copy()\n",
    "scaled_data[cols] = scaler.fit_transform(scaled_data[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce7c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare the dataset for training: Sequence data for LSTM\n",
    "def create_sequences(data, seq_length=10):\n",
    "    sequences = []\n",
    "    targets   = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # inputs: 10×5 features\n",
    "        sequences.append(data.iloc[i:i+seq_length][features].values)\n",
    "        # outputs: 5 dims\n",
    "        targets.append(data.iloc[i+seq_length][target].values)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# 4. Create sequences for training\n",
    "X, y = create_sequences(scaled_data, seq_length=10)\n",
    "\n",
    "# 5. Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 6. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cfb9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0161\n",
      "Epoch [2/100], Loss: 0.0134\n",
      "Epoch [3/100], Loss: 0.0153\n",
      "Epoch [4/100], Loss: 0.0160\n",
      "Epoch [5/100], Loss: 0.0210\n",
      "Epoch [6/100], Loss: 0.0133\n",
      "Epoch [7/100], Loss: 0.0160\n",
      "Epoch [8/100], Loss: 0.0165\n",
      "Epoch [9/100], Loss: 0.0159\n",
      "Epoch [10/100], Loss: 0.0133\n",
      "Epoch [11/100], Loss: 0.0187\n",
      "Epoch [12/100], Loss: 0.0145\n",
      "Epoch [13/100], Loss: 0.0169\n",
      "Epoch [14/100], Loss: 0.0125\n",
      "Epoch [15/100], Loss: 0.0149\n",
      "Epoch [16/100], Loss: 0.0136\n",
      "Epoch [17/100], Loss: 0.0185\n",
      "Epoch [18/100], Loss: 0.0163\n",
      "Epoch [19/100], Loss: 0.0166\n",
      "Epoch [20/100], Loss: 0.0147\n",
      "Epoch [21/100], Loss: 0.0156\n",
      "Epoch [22/100], Loss: 0.0223\n",
      "Epoch [23/100], Loss: 0.0126\n",
      "Epoch [24/100], Loss: 0.0184\n",
      "Epoch [25/100], Loss: 0.0181\n",
      "Epoch [26/100], Loss: 0.0195\n",
      "Epoch [27/100], Loss: 0.0128\n",
      "Epoch [28/100], Loss: 0.0132\n",
      "Epoch [29/100], Loss: 0.0136\n",
      "Epoch [30/100], Loss: 0.0156\n",
      "Epoch [31/100], Loss: 0.0206\n",
      "Epoch [32/100], Loss: 0.0144\n",
      "Epoch [33/100], Loss: 0.0193\n",
      "Epoch [34/100], Loss: 0.0150\n",
      "Epoch [35/100], Loss: 0.0190\n",
      "Epoch [36/100], Loss: 0.0162\n",
      "Epoch [37/100], Loss: 0.0144\n",
      "Epoch [38/100], Loss: 0.0159\n",
      "Epoch [39/100], Loss: 0.0207\n",
      "Epoch [40/100], Loss: 0.0161\n",
      "Epoch [41/100], Loss: 0.0142\n",
      "Epoch [42/100], Loss: 0.0189\n",
      "Epoch [43/100], Loss: 0.0133\n",
      "Epoch [44/100], Loss: 0.0136\n",
      "Epoch [45/100], Loss: 0.0146\n",
      "Epoch [46/100], Loss: 0.0184\n",
      "Epoch [47/100], Loss: 0.0139\n",
      "Epoch [48/100], Loss: 0.0126\n",
      "Epoch [49/100], Loss: 0.0160\n",
      "Epoch [50/100], Loss: 0.0163\n",
      "Epoch [51/100], Loss: 0.0139\n",
      "Epoch [52/100], Loss: 0.0180\n",
      "Epoch [53/100], Loss: 0.0178\n",
      "Epoch [54/100], Loss: 0.0129\n",
      "Epoch [55/100], Loss: 0.0140\n",
      "Epoch [56/100], Loss: 0.0160\n",
      "Epoch [57/100], Loss: 0.0149\n",
      "Epoch [58/100], Loss: 0.0173\n",
      "Epoch [59/100], Loss: 0.0141\n",
      "Epoch [60/100], Loss: 0.0188\n",
      "Epoch [61/100], Loss: 0.0147\n",
      "Epoch [62/100], Loss: 0.0191\n",
      "Epoch [63/100], Loss: 0.0183\n",
      "Epoch [64/100], Loss: 0.0149\n",
      "Epoch [65/100], Loss: 0.0146\n",
      "Epoch [66/100], Loss: 0.0139\n",
      "Epoch [67/100], Loss: 0.0177\n",
      "Epoch [68/100], Loss: 0.0153\n",
      "Epoch [69/100], Loss: 0.0142\n",
      "Epoch [70/100], Loss: 0.0176\n",
      "Epoch [71/100], Loss: 0.0154\n",
      "Epoch [72/100], Loss: 0.0135\n",
      "Epoch [73/100], Loss: 0.0150\n",
      "Epoch [74/100], Loss: 0.0129\n",
      "Epoch [75/100], Loss: 0.0124\n",
      "Epoch [76/100], Loss: 0.0156\n",
      "Epoch [77/100], Loss: 0.0140\n",
      "Epoch [78/100], Loss: 0.0199\n",
      "Epoch [79/100], Loss: 0.0124\n",
      "Epoch [80/100], Loss: 0.0199\n",
      "Epoch [81/100], Loss: 0.0190\n",
      "Epoch [82/100], Loss: 0.0131\n",
      "Epoch [83/100], Loss: 0.0170\n",
      "Epoch [84/100], Loss: 0.0181\n",
      "Epoch [85/100], Loss: 0.0180\n",
      "Epoch [86/100], Loss: 0.0178\n",
      "Epoch [87/100], Loss: 0.0127\n",
      "Epoch [88/100], Loss: 0.0147\n",
      "Epoch [89/100], Loss: 0.0138\n",
      "Epoch [90/100], Loss: 0.0167\n",
      "Epoch [91/100], Loss: 0.0128\n",
      "Epoch [92/100], Loss: 0.0166\n",
      "Epoch [93/100], Loss: 0.0125\n",
      "Epoch [94/100], Loss: 0.0165\n",
      "Epoch [95/100], Loss: 0.0157\n",
      "Epoch [96/100], Loss: 0.0125\n",
      "Epoch [97/100], Loss: 0.0130\n",
      "Epoch [98/100], Loss: 0.0124\n",
      "Epoch [99/100], Loss: 0.0150\n",
      "Epoch [100/100], Loss: 0.0132\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Print evaluation results\u001b[39;00m\n\u001b[32m     60\u001b[39m y_pred = y_pred.numpy()\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m y_test = \u001b[43my_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m()\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Show some sample predictions vs actuals\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the LSTM model in PyTorch\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take the last output for prediction\n",
    "        return out\n",
    "\n",
    "# Set parameters for the model\n",
    "input_size = len(features)\n",
    "hidden_size = 128\n",
    "output_size = len(target)  # 5 outputs: lat, lon, velocity_x, velocity_y, gradient_info\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    permutation = torch.randperm(X_train.size(0))\n",
    "\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x, batch_y = X_train[indices], y_train[indices]\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "\n",
    "# Print evaluation results\n",
    "y_pred = y_pred.numpy()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "\n",
    "# Show some sample predictions vs actuals\n",
    "for i in range(5):\n",
    "    print(f\"Prediction: {y_pred[i]}, Actual: {y_test[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
